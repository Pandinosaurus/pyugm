## 24 January 2015
It seems that damping beliefs in a loopy graph is very useful, but not useful enough - especially for a grid.
Therefore need to add a sampling/variational/etc inference class. Might go with Gibbs sampler first.

## 17 December 2014
Apparently you have to normalize the factors when the graph has loops.

## 4 November 2014
Since the shape of data give the cardinalities, it can be omitted when specifying DiscreteFactor.

## 29 October 2014
Tidy up stuff - examples, docs, run pylint, etc

## 20 October 2014
Report approximate ll, evidence each iteration.
Learn with approximate gradient for first few iterations.
Do whole update function with numba.
Does distribute/collect work with non-trees?

## 11 October 2014
Document as clique templates (from Sutton and McCallum's tutorial)

## 27 September 2014
Optimise for speed. - Numba looks like it is working. Add Numba update function.
Flooding protocol is slow - build distribute/collect protocol for trees.

## 17 September 2014
Example HMM.

## 14 September 2014
Running into numerical problems - time to factor out the normalising constant.
This will complicate testing - for now replace existing data tests with data * constant.
For new tests use accessor methods.
Wondering about architecture - should only inplace updates be allowed?

## 3 July 2014
Looks like I'm rather going with un-normalised models first.
Gaussian prior.
Factors should now be parametrised - add place where parameter variables can be added to a factor.
Use BFGS to find MAP
Then approximate posterior with Laplace approximation using Hessian returned by BFGS.

## 1 July 2014
Maybe concentrate on getting a discrete bayesian network going first.
Factor out the update ordering.
Add gaussian priors [rather dirichlet priors?] - variable and conditional. (Variational/expectation update?)
Add plates - update order should take this into account.
Plates for dynamic models.
Clusters?

