## 5 July 2015
Move everything that mutates the model out to an Inference object - the model shouldn't change.
Maybe it will be possible to re-use previous inference results with a slightly changed model?
Differentiate between factors and beliefs. Beliefs are mutable factors.

## 25 February 2015
Figuring out how to approximate Z if I already have approximate cluster beliefs - looks like just evaluating the
factored energy functional at these beliefs. One problem with this is that we need the original potentials - which
are destroyed because we're doing belief updates. So possibly add 'potential' and 'belief' tables to each factor. Other
option is to keep potentials with the model/factors, and beliefs with the inference object.

## 12 February 2015
Fixed a long standing bug with belief updates. Get Z approximation from model so we can learn some parameters in loopy
graphs.

## 24 January 2015
It seems that damping beliefs in a loopy graph is very useful, but not useful enough - especially for a grid.
Therefore need to add a sampling/variational/etc inference class. Might go with Gibbs sampler first.

## 17 December 2014
Apparently you have to normalize the factors when the graph has loops.

## 4 November 2014
Since the shape of data give the cardinalities, it can be omitted when specifying DiscreteFactor.

## 29 October 2014
Tidy up stuff - examples, docs, run pylint, etc

## 20 October 2014
Report approximate ll, evidence each iteration.
Learn with approximate gradient for first few iterations.
Do whole update function with numba.
Does distribute/collect work with non-trees?

## 11 October 2014
Document as clique templates (from Sutton and McCallum's tutorial)

## 27 September 2014
Optimise for speed. - Numba looks like it is working. Add Numba update function.
Flooding protocol is slow - build distribute/collect protocol for trees.

## 17 September 2014
Example HMM.

## 14 September 2014
Running into numerical problems - time to factor out the normalising constant.
This will complicate testing - for now replace existing data tests with data * constant.
For new tests use accessor methods.
Wondering about architecture - should only inplace updates be allowed?

## 3 July 2014
Looks like I'm rather going with un-normalised models first.
Gaussian prior.
Factors should now be parametrised - add place where parameter variables can be added to a factor.
Use BFGS to find MAP
Then approximate posterior with Laplace approximation using Hessian returned by BFGS.

## 1 July 2014
Maybe concentrate on getting a discrete bayesian network going first.
Factor out the update ordering.
Add gaussian priors [rather dirichlet priors?] - variable and conditional. (Variational/expectation update?)
Add plates - update order should take this into account.
Plates for dynamic models.
Clusters?

